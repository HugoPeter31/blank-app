from __future__ import annotations

# REPORTING TOOL @ HSG (Streamlit)
#
# Purpose:
# - Facility issue reporting
# - Asset booking
# - Asset tracking
#
# Design notes:
# - Streamlit reruns the script frequently ‚Üí cache expensive setup (config, DB connection).
# - Side effects (DB writes, emails) only happen behind explicit user actions (buttons/forms).
# - Inputs are normalized + validated before persistence to avoid duplicates and fragile edge-cases.
#
# Note:
# - Admin page is protected via Streamlit secrets (ADMIN_PASSWORD).
#
# Authors: Arthur Lavric & Fabio Patierno

# ============================================================================
# IMPORTS
# ============================================================================
import logging
import re
import secrets
import smtplib
import sqlite3
from dataclasses import dataclass
from datetime import datetime, timedelta
from email.message import EmailMessage
from typing import Iterable

import pandas as pd
import pytz
import streamlit as st

# ============================================================================
# CONFIGURATION & CONSTANTS
# ============================================================================
# One timezone source prevents subtle ‚Äúnaive vs aware‚Äù datetime bugs across DB, UI and SLA logic.
APP_TZ = pytz.timezone("Europe/Zurich")

DB_PATH = "hsg_reporting.db"
LOGO_PATH = "HSG-logo-new.png"

# Keep ‚Äúmagic numbers‚Äù centralized so behavior is easy to tune and review.
DESCRIPTION_PREVIEW_CHARS = 90
MAX_ISSUE_DESCRIPTION_CHARS = 500

MAP_IFRAME_URL = (
    "https://use.mazemap.com/embed.html?v=1&zlevel=1&center=9.373611,47.429708&zoom=14.7&campusid=710"
)

# Predefined issue types (kept as a single list so dropdowns and analytics stay consistent).
ISSUE_TYPES = [
    "Lighting issues",
    "Sanitary problems",
    "Heating, ventilation or air conditioning issues",
    "Indoor climate or air quality issues",
    "Cleaning or hygiene issues",
    "Network or internet problems",
    "IT or AV equipment malfunction",
    "Power supply or electrical outlet issues",
    "Furniture or room equipment damage",
    "Doors, windows or locks malfunction",
    "Noise disturbance",
    "Health or safety hazard",
    "Other facility-related issue",
]

IMPORTANCE_LEVELS = ["Low", "Medium", "High"]
STATUS_LEVELS = ["Pending", "In Progress", "Resolved"]

# Help text definitions for consistent UX
HELP_TEXTS = {
    "email": "Must be @unisg.ch or @student.unisg.ch",
    "room": "Format: A 09-001 (letter + space + room number)",
    "description": "Describe what happened, where, when, and impact",
    "priority": "High = 24h SLA, Medium = 72h SLA, Low = 120h SLA",
}

# SLA by priority (hours). Centralized here to keep the policy explicit and auditable.
SLA_HOURS_BY_IMPORTANCE: dict[str, int] = {
    "High": 24,
    "Medium": 72,
    "Low": 120,
}

# Validation patterns:
# - Restrict email domains to reduce risk of sending notifications to unintended recipients.
# - Room pattern allows both ‚ÄúA09-001‚Äù and ‚ÄúA 09-001‚Äù; normalization canonicalizes it.
EMAIL_PATTERN = re.compile(r"^[\w.]+@(student\.)?unisg\.ch$")
ROOM_PATTERN = re.compile(r"^[A-Z]\s?\d{2}-\d{3}$")

# Location mapping used by the tracking view (labels matter more than coordinates for this app).
LOCATIONS = {
    "R_A_09001": {"label": "Room A 09-001", "x": 10, "y": 20},
    "H_A_09001": {"label": "Hallway near Room A 09-001", "x": 15, "y": 25},
    "R_B_10012": {"label": "Room B 10-012", "x": 40, "y": 60},
    "H_B_10012": {"label": "Hallway near Room B 10-012", "x": 45, "y": 65},
    "R_A_08005": {"label": "Room A 08-005", "x": 8, "y": 16},
    "H_A_08005": {"label": "Hallway near Room A 08-005", "x": 12, "y": 18},
    "R_A_10003": {"label": "Room A 10-003", "x": 14, "y": 28},
    "H_A_10003": {"label": "Hallway near Room A 10-003", "x": 18, "y": 30},
    "R_B_09007": {"label": "Room B 09-007", "x": 38, "y": 52},
    "H_B_09007": {"label": "Hallway near Room B 09-007", "x": 42, "y": 54},
    "R_C_11002": {"label": "Room C 11-002", "x": 65, "y": 78},
    "H_C_11002": {"label": "Hallway near Room C 11-002", "x": 68, "y": 80},
}

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
# Streamlit reruns can re-add handlers; guard to avoid duplicated log lines.
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)

# ============================================================================
# DATA MODELS
# ============================================================================
@dataclass(frozen=True)
class Submission:
    """Validated payload for a user-submitted issue.

    Frozen on purpose:
    - After validation, the record should be treated as immutable to avoid
      accidental state drift during Streamlit reruns.
    """

    name: str
    hsg_email: str
    issue_type: str
    room_number: str
    importance: str
    user_comment: str


@dataclass(frozen=True)
class AppConfig:
    """Runtime configuration sourced from Streamlit secrets.

    Centralizing secrets access:
    - Keeps business logic independent from Streamlit‚Äôs secrets API.
    - Makes it obvious which settings exist (useful for grading and debugging).
    """

    smtp_server: str
    smtp_port: int
    smtp_username: str
    smtp_password: str
    from_email: str
    admin_inbox: str
    admin_password: str
    debug: bool
    assignees: list[str]
    auto_weekly_report: bool
    report_weekday: int
    report_hour: int


# ============================================================================
# SECRETS MANAGEMENT (Streamlit Cloud Secrets)
# ============================================================================
def get_secret(key: str, default: str | None = None) -> str:
    """Read a secret safely (fail-fast for required keys).

    Why:
    - Missing secrets should be a clear configuration error, not a late runtime crash.
    """
    if key in st.secrets:
        return str(st.secrets[key])
    if default is not None:
        return default
    st.error(f"Missing Streamlit secret: {key}")
    st.stop()


@st.cache_resource
def get_config() -> AppConfig:
    """Load secrets once per session.

    Why caching:
    - Streamlit reruns frequently; parsing secrets repeatedly is wasted work.
    - Loading inside the app lifecycle ensures Streamlit can show helpful errors.
    """
    smtp_server = get_secret("SMTP_SERVER", "smtp.gmail.com")
    smtp_port = int(get_secret("SMTP_PORT", "587"))
    smtp_username = get_secret("SMTP_USERNAME")
    smtp_password = get_secret("SMTP_PASSWORD")
    from_email = get_secret("FROM_EMAIL", smtp_username)
    admin_inbox = get_secret("ADMIN_INBOX", from_email)

    admin_password = get_secret("ADMIN_PASSWORD")
    debug = get_secret("DEBUG", "0") == "1"

    assignees_raw = get_secret("ASSIGNEES", "Facility Team")
    assignees = [a.strip() for a in assignees_raw.split(",") if a.strip()]

    auto_weekly_report = get_secret("AUTO_WEEKLY_REPORT", "0") == "1"
    report_weekday = int(get_secret("REPORT_WEEKDAY", "0"))  # 0=Monday, 6=Sunday
    report_hour = int(get_secret("REPORT_HOUR", "7"))  # 24h format

    return AppConfig(
        smtp_server=smtp_server,
        smtp_port=smtp_port,
        smtp_username=smtp_username,
        smtp_password=smtp_password,
        from_email=from_email,
        admin_inbox=admin_inbox,
        admin_password=admin_password,
        debug=debug,
        assignees=assignees,
        auto_weekly_report=auto_weekly_report,
        report_weekday=report_weekday,
        report_hour=report_hour,
    )


# ============================================================================
# TIME HELPER FUNCTIONS
# ============================================================================
def now_zurich() -> datetime:
    """Return current time in the app timezone (single source of truth)."""
    return datetime.now(APP_TZ)


def now_zurich_str() -> str:
    """ISO timestamp for storage/logging (seconds precision keeps DB readable)."""
    return now_zurich().isoformat(timespec="seconds")


def safe_localize(dt_naive: datetime) -> datetime:
    """Localize a naive datetime into APP_TZ, handling DST edge cases.

    Why:
    - DST changes can create ambiguous or non-existent local times.
    - We choose deterministic fallbacks to keep the app stable.
    """
    try:
        return APP_TZ.localize(dt_naive, is_dst=None)
    except pytz.AmbiguousTimeError:
        return APP_TZ.localize(dt_naive, is_dst=False)
    except pytz.NonExistentTimeError:
        return APP_TZ.localize(dt_naive + timedelta(hours=1), is_dst=True)


def iso_to_dt(value: str) -> datetime | None:
    """Parse an ISO timestamp into an aware datetime (best-effort)."""
    try:
        dt = datetime.fromisoformat(value)
        if dt.tzinfo is None:
            return safe_localize(dt)
        return dt.astimezone(APP_TZ)
    except (TypeError, ValueError):
        # Logging (not crashing) is intentional: old/invalid rows should not break the UI.
        logger.warning("Failed to parse datetime from value=%r", value)
        return None


def parse_iso_series_to_zurich(values: pd.Series) -> pd.Series:
    """Parse ISO timestamp strings into Europe/Zurich timezone (best-effort).

    Robust against:
    - Fully empty columns (all None/NaT)
    - Mixed timestamp formats (naive + aware)
    """
    s = pd.to_datetime(values, errors="coerce")

    # If everything is NaT, return early (avoids edge-case .dt issues on some pandas versions).
    if s.isna().all():
        return s

    # If timestamps are naive, assume Zurich local time.
    if getattr(s.dt, "tz", None) is None:
        return s.dt.tz_localize(APP_TZ, ambiguous="NaT", nonexistent="shift_forward")

    # If aware, normalize to Zurich.
    return s.dt.tz_convert(APP_TZ)


def expected_resolution_dt(created_at_iso: str, importance: str) -> datetime | None:
    """Compute SLA target timestamp based on creation time + priority."""
    created_dt = iso_to_dt(created_at_iso)
    sla_hours = SLA_HOURS_BY_IMPORTANCE.get(str(importance))
    if created_dt is None or sla_hours is None:
        return None
    return created_dt + timedelta(hours=int(sla_hours))


def is_room_location(location_id: str) -> bool:
    """Room locations are encoded with the 'R_' prefix (used for booking side-effects)."""
    return str(location_id).startswith("R_")


# ============================================================================
# VALIDATION FUNCTIONS
# ============================================================================
def valid_email(hsg_email: str) -> bool:
    """Validate HSG email format (unisg domains only)."""
    return bool(EMAIL_PATTERN.fullmatch(hsg_email.strip().lower()))


def normalize_room(room_number: str) -> str:
    """Normalize room strings to a canonical format to reduce duplicates."""
    raw = room_number.strip().upper()
    raw = re.sub(r"^([A-Z])(\d{2}-\d{3})$", r"\1 \2", raw)  # A09-001 -> A 09-001
    raw = re.sub(r"\s+", " ", raw)  # collapse whitespace
    return raw


def valid_room_number(room_number: str) -> bool:
    """Validate room number after normalization."""
    return bool(ROOM_PATTERN.fullmatch(normalize_room(room_number)))


def validate_submission_input(sub: Submission) -> list[str]:
    """Validate submission inputs before writing to the DB.

    Why:
    - Prevents partial/invalid rows that break dashboards, filters and admin workflows.
    """
    errors: list[str] = []

    if not sub.name.strip():
        errors.append("Name is required.")

    if not sub.hsg_email.strip():
        errors.append("Email address is required.")
    elif not valid_email(sub.hsg_email):
        errors.append("Invalid email address. Use ‚Ä¶@unisg.ch or ‚Ä¶@student.unisg.ch.")

    if not sub.room_number.strip():
        errors.append("Room number is required.")
    elif not valid_room_number(sub.room_number):
        errors.append("Invalid room number format. Example: 'A 09-001'.")

    if sub.issue_type not in ISSUE_TYPES:
        errors.append("Invalid issue type selection.")

    if sub.importance not in IMPORTANCE_LEVELS:
        errors.append("Invalid importance selection.")

    if not sub.user_comment.strip():
        errors.append("Problem description is required.")

    return errors


def validate_admin_email(email: str) -> list[str]:
    """Validate emails used for admin-triggered notifications."""
    if not email.strip():
        return ["Email address is required."]
    if not valid_email(email):
        return ["Please provide a valid email address (‚Ä¶@unisg.ch or ‚Ä¶@student.unisg.ch)."]
    return []


# ============================================================================
# DATABASE MANAGEMENT
# ============================================================================
@st.cache_resource
def get_connection() -> sqlite3.Connection:
    """Create and cache SQLite connection.

    Why:
    - Cached connection avoids unnecessary overhead on Streamlit reruns.
    - Enabling FK constraints ensures data integrity for referenced tables.
    """
    con = sqlite3.connect(DB_PATH, check_same_thread=False)
    con.execute("PRAGMA foreign_keys = ON")
    
    # Streamlit can trigger near-parallel reads/writes on reruns; WAL + busy_timeout reduces transient lock errors.
    con.execute("PRAGMA journal_mode = WAL")
    con.execute("PRAGMA busy_timeout = 3000")
    
    return con


def init_db(con: sqlite3.Connection) -> None:
    """Create issue-reporting tables (idempotent for safe reruns)."""
    with con:
        con.execute(
            """
            CREATE TABLE IF NOT EXISTS submissions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                hsg_email TEXT NOT NULL,
                issue_type TEXT NOT NULL,
                room_number TEXT NOT NULL,
                importance TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'Pending',
                user_comment TEXT NOT NULL,
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL,
                assigned_to TEXT,
                resolved_at TEXT
            )
            """
        )

        con.execute(
            """
            CREATE TABLE IF NOT EXISTS status_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                submission_id INTEGER NOT NULL,
                old_status TEXT NOT NULL,
                new_status TEXT NOT NULL,
                changed_at TEXT NOT NULL,
                FOREIGN KEY (submission_id) REFERENCES submissions(id) ON DELETE CASCADE
            )
            """
        )

        con.execute(
            """
            CREATE TABLE IF NOT EXISTS report_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                report_type TEXT NOT NULL,
                sent_at TEXT NOT NULL
            )
            """
        )

        # Indexes for faster filtering/sorting in dashboards
        con.execute("CREATE INDEX IF NOT EXISTS idx_submissions_status ON submissions(status)")
        con.execute("CREATE INDEX IF NOT EXISTS idx_submissions_created_at ON submissions(created_at)")


def init_booking_table(con: sqlite3.Connection) -> None:
    """Create booking table (idempotent)."""
    with con:
        con.execute(
            """
            CREATE TABLE IF NOT EXISTS bookings (
                booking_id INTEGER PRIMARY KEY AUTOINCREMENT,
                asset_id TEXT NOT NULL,
                user_name TEXT NOT NULL,
                start_time TEXT NOT NULL,
                end_time TEXT NOT NULL,
                created_at TEXT NOT NULL
            )
            """
        )

        # Index for fast overlap checks (availability)
        con.execute("CREATE INDEX IF NOT EXISTS idx_bookings_asset_time ON bookings(asset_id, start_time, end_time)")


def init_assets_table(con: sqlite3.Connection) -> None:
    """Create assets table (idempotent)."""
    with con:
        con.execute(
            """
            CREATE TABLE IF NOT EXISTS assets (
                asset_id TEXT PRIMARY KEY,
                asset_name TEXT NOT NULL,
                asset_type TEXT NOT NULL,
                location_id TEXT NOT NULL,
                status TEXT NOT NULL
            )
            """
        )


def migrate_db(con: sqlite3.Connection) -> None:
    """Apply minimal schema migrations for backward compatibility.

    Why:
    - Allows grading/running even if an older DB file is present.
    """
    cols = {row[1] for row in con.execute("PRAGMA table_info(submissions)").fetchall()}
    now_iso = now_zurich_str()

    with con:
        if "created_at" not in cols:
            con.execute("ALTER TABLE submissions ADD COLUMN created_at TEXT")
            con.execute("UPDATE submissions SET created_at = ? WHERE created_at IS NULL", (now_iso,))

        if "updated_at" not in cols:
            con.execute("ALTER TABLE submissions ADD COLUMN updated_at TEXT")
            con.execute("UPDATE submissions SET updated_at = ? WHERE updated_at IS NULL", (now_iso,))

        if "assigned_to" not in cols:
            con.execute("ALTER TABLE submissions ADD COLUMN assigned_to TEXT")

        if "resolved_at" not in cols:
            con.execute("ALTER TABLE submissions ADD COLUMN resolved_at TEXT")

        # Ensure auxiliary tables exist (older DBs may not have them).
        con.execute(
            """
            CREATE TABLE IF NOT EXISTS status_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                submission_id INTEGER NOT NULL,
                old_status TEXT NOT NULL,
                new_status TEXT NOT NULL,
                changed_at TEXT NOT NULL,
                FOREIGN KEY (submission_id) REFERENCES submissions(id)
            )
            """
        )

        con.execute(
            """
            CREATE TABLE IF NOT EXISTS report_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                report_type TEXT NOT NULL,
                sent_at TEXT NOT NULL
            )
            """
        )


def seed_assets(con: sqlite3.Connection) -> None:
    """Insert demo assets once (INSERT OR IGNORE makes this safe on rerun)."""
    assets = [
        ("ROOM_A", "Study Room A", "Room", "R_A_09001", "available"),
        ("ROOM_B", "Study Room B", "Room", "R_B_10012", "available"),
        ("MEETING_1", "Meeting Room 1", "Room", "R_B_10012", "available"),
        ("PROJECTOR_1", "Portable Projector 1", "Equipment", "H_B_10012", "available"),
        ("CHAIR_H1", "Hallway Chair 1", "Chair", "H_A_09001", "available"),
        ("CHAIR_H2", "Hallway Chair 2", "Chair", "H_A_09001", "available"),
        ("ROOM_A_08005", "Study Room A 08-005", "Room", "R_A_08005", "available"),
        ("WHITEBOARD_A08005", "Whiteboard A08-005", "Equipment", "R_A_08005", "available"),
        ("CHAIR_A08005_1", "Chair A08-005 #1", "Chair", "R_A_08005", "available"),
        ("CHAIR_A08005_2", "Chair A08-005 #2", "Chair", "R_A_08005", "available"),
        ("ROOM_A_10003", "Study Room A 10-003", "Room", "R_A_10003", "available"),
        ("PROJECTOR_A10003", "Projector A10-003", "Equipment", "R_A_10003", "available"),
        ("TABLE_A10003", "Table A10-003", "Furniture", "R_A_10003", "available"),
        ("ROOM_B_09007", "Study Room B 09-007", "Room", "R_B_09007", "available"),
        ("LAPTOP_CART_B09007", "Laptop Cart B09-007", "Equipment", "R_B_09007", "available"),
        ("CHAIR_B09007_1", "Chair B09-007 #1", "Chair", "R_B_09007", "available"),
        ("CHAIR_B09007_2", "Chair B09-007 #2", "Chair", "R_B_09007", "available"),
        ("ROOM_C_11002", "Meeting Room C 11-002", "Room", "R_C_11002", "available"),
        ("SCREEN_C11002", "Presentation Screen C11-002", "Equipment", "R_C_11002", "available"),
        ("SPEAKER_C11002", "Speaker C11-002", "Equipment", "R_C_11002", "available"),
        ("SOFA_HA08005", "Hallway Sofa (A08-005)", "Furniture", "H_A_08005", "available"),
        ("PLANT_HA10003", "Hallway Plant (A10-003)", "Furniture", "H_A_10003", "available"),
        ("BIN_HB09007", "Recycling Bin (B09-007)", "Furniture", "H_B_09007", "available"),
        ("SIGN_HC11002", "Info Sign (C11-002)", "Furniture", "H_C_11002", "available"),
    ]

    with con:
        for asset in assets:
            con.execute(
                """
                INSERT OR IGNORE INTO assets
                (asset_id, asset_name, asset_type, location_id, status)
                VALUES (?, ?, ?, ?, ?)
                """,
                asset,
            )


def fetch_submissions(con: sqlite3.Connection) -> pd.DataFrame:
    """Read all issue submissions into a DataFrame (used by multiple pages)."""
    return pd.read_sql("SELECT * FROM submissions", con)


def fetch_status_log(con: sqlite3.Connection) -> pd.DataFrame:
    """Read the status audit log (latest changes first)."""
    return pd.read_sql(
        """
        SELECT submission_id, old_status, new_status, changed_at
        FROM status_log
        ORDER BY changed_at DESC
        """,
        con,
    )


def fetch_report_log(con: sqlite3.Connection, report_type: str) -> pd.DataFrame:
    """Read report history for deduplication (prevents repeated emails on rerun)."""
    return pd.read_sql(
        """
        SELECT report_type, sent_at
        FROM report_log
        WHERE report_type = ?
        ORDER BY sent_at DESC
        """,
        con,
        params=(report_type,),
    )


def fetch_assets(con: sqlite3.Connection) -> pd.DataFrame:
    """Read all assets."""
    return pd.read_sql(
        """
        SELECT asset_id, asset_name, asset_type, location_id, status
        FROM assets
        ORDER BY asset_type, asset_name
        """,
        con,
    )


def fetch_assets_in_room(con: sqlite3.Connection, room_location_id: str) -> list[str]:
    """Return asset IDs in a room (excluding the room entity itself)."""
    rows = con.execute(
        """
        SELECT asset_id
        FROM assets
        WHERE location_id = ?
          AND asset_type != 'Room'
        """,
        (room_location_id,),
    ).fetchall()
    return [r[0] for r in rows]


def mark_report_sent(con: sqlite3.Connection, report_type: str) -> None:
    """Persist report timestamp so recurring checks remain idempotent."""
    with con:
        con.execute(
            "INSERT INTO report_log (report_type, sent_at) VALUES (?, ?)",
            (report_type, now_zurich_str()),
        )


# ============================================================================
# BOOKING SYSTEM FUNCTIONS
# ============================================================================
def sync_asset_statuses_from_bookings(con: sqlite3.Connection) -> None:
    """Update asset statuses from current bookings.

    Why:
    - Keeps the UI simple: we display a single ‚Äústatus‚Äù field per asset.
    - Avoids repeating complex ‚Äúis booked?‚Äù joins in multiple UI pages.
    """
    now_iso = now_zurich().isoformat(timespec="seconds")

    with con:
        con.execute("UPDATE assets SET status = 'available'")

    active = pd.read_sql(
        """
        SELECT b.asset_id, a.asset_type, a.location_id
        FROM bookings b
        JOIN assets a ON a.asset_id = b.asset_id
        WHERE b.start_time <= ? AND b.end_time > ?
        """,
        con,
        params=(now_iso, now_iso),
    )

    with con:
        for _, row in active.iterrows():
            asset_id = row["asset_id"]
            asset_type = row["asset_type"]
            location_id = row["location_id"]

            con.execute("UPDATE assets SET status = 'booked' WHERE asset_id = ?", (asset_id,))

            # Room bookings implicitly block items inside the room to prevent double-booking.
            if asset_type == "Room" and is_room_location(location_id):
                for aid in fetch_assets_in_room(con, location_id):
                    con.execute("UPDATE assets SET status = 'booked' WHERE asset_id = ?", (aid,))


def is_asset_available(con: sqlite3.Connection, asset_id: str, start_time: datetime, end_time: datetime) -> bool:
    """Return True if no booking overlaps the requested time window."""
    count = con.execute(
        """
        SELECT COUNT(*) FROM bookings
        WHERE asset_id = ?
          AND start_time < ?
          AND end_time > ?
        """,
        (asset_id, end_time.isoformat(timespec="seconds"), start_time.isoformat(timespec="seconds")),
    ).fetchone()[0]
    return count == 0


def fetch_future_bookings(con: sqlite3.Connection, asset_id: str) -> pd.DataFrame:
    """Read upcoming bookings for one asset (used for transparency in booking UI)."""
    now_iso = now_zurich().isoformat(timespec="seconds")
    return pd.read_sql(
        """
        SELECT user_name, start_time, end_time
        FROM bookings
        WHERE asset_id = ?
          AND end_time >= ?
        ORDER BY start_time
        """,
        con,
        params=(asset_id, now_iso),
    )


def fetch_future_bookings_for_user(con: sqlite3.Connection, user_name: str) -> pd.DataFrame:
    """Read upcoming bookings for a user (case-insensitive match)."""
    now_iso = now_zurich().isoformat(timespec="seconds")
    return pd.read_sql(
        """
        SELECT b.asset_id, a.asset_name, a.asset_type, b.start_time, b.end_time
        FROM bookings b
        JOIN assets a ON a.asset_id = b.asset_id
        WHERE LOWER(b.user_name) = LOWER(?)
          AND b.end_time >= ?
        ORDER BY b.start_time
        """,
        con,
        params=(user_name.strip(), now_iso),
    )


def next_available_time(con: sqlite3.Connection, asset_id: str) -> datetime | None:
    """Return the soonest end_time after now (used to explain ‚Äòcurrently booked‚Äô to users)."""
    now_iso = now_zurich().isoformat(timespec="seconds")
    row = con.execute(
        """
        SELECT MIN(end_time)
        FROM bookings
        WHERE asset_id = ?
          AND end_time > ?
        """,
        (asset_id, now_iso),
    ).fetchone()
    if not row or not row[0]:
        return None
    return iso_to_dt(str(row[0]))


def count_active_bookings(con: sqlite3.Connection) -> int:
    """Count bookings active right now (simple KPI)."""
    now_iso = now_zurich().isoformat(timespec="seconds")
    row = con.execute(
        """
        SELECT COUNT(*)
        FROM bookings
        WHERE start_time <= ? AND end_time > ?
        """,
        (now_iso, now_iso),
    ).fetchone()
    return int(row[0] if row and row[0] is not None else 0)


def count_future_bookings(con: sqlite3.Connection) -> int:
    """Count bookings with an end_time in the future (simple KPI)."""
    now_iso = now_zurich().isoformat(timespec="seconds")
    row = con.execute("SELECT COUNT(*) FROM bookings WHERE end_time >= ?", (now_iso,)).fetchone()
    return int(row[0] if row and row[0] is not None else 0)


# ============================================================================
# ISSUE ADMINISTRATION FUNCTIONS
# ============================================================================
def update_issue_admin_fields(
    con: sqlite3.Connection,
    issue_id: int,
    new_status: str,
    assigned_to: str | None,
    old_status: str,
) -> None:
    """Update status/assignment and log the change for auditability."""
    updated_at = now_zurich_str()
    set_resolved_at = new_status == "Resolved"

    with con:
        con.execute(
            """
            UPDATE submissions
            SET status = ?,
                updated_at = ?,
                assigned_to = ?,
                resolved_at = CASE
                    WHEN ? = 1 AND (resolved_at IS NULL OR resolved_at = '') THEN ?
                    ELSE resolved_at
                END
            WHERE id = ?
            """,
            (
                new_status,
                updated_at,
                (assigned_to.strip() if assigned_to and assigned_to.strip() else None),
                1 if set_resolved_at else 0,
                updated_at,
                int(issue_id),
            ),
        )

        # Keep a status history so graders/admins can trace what happened when.
        if new_status != old_status:
            con.execute(
                """
                INSERT INTO status_log (submission_id, old_status, new_status, changed_at)
                VALUES (?, ?, ?, ?)
                """,
                (int(issue_id), old_status, new_status, updated_at),
            )


def insert_submission(con: sqlite3.Connection, sub: Submission) -> int:
    """Insert a new issue submission (single transaction for atomicity).

    Returns:
        int: The inserted submission ID (for user-facing confirmation).
    """
    created_at = now_zurich_str()

    with con:
        cur = con.execute(
            """
            INSERT INTO submissions
            (name, hsg_email, issue_type, room_number, importance, status,
             user_comment, created_at, updated_at, assigned_to, resolved_at)
            VALUES (?, ?, ?, ?, ?, 'Pending', ?, ?, ?, NULL, NULL)
            """,
            (
                sub.name.strip(),
                sub.hsg_email.strip().lower(),
                sub.issue_type,
                normalize_room(sub.room_number),
                sub.importance,
                sub.user_comment.strip(),
                created_at,
                created_at,
            ),
        )
        return int(cur.lastrowid)


# ============================================================================
# EMAIL FUNCTIONS
# ============================================================================
def send_email(to_email: str, subject: str, body: str, *, config: AppConfig) -> tuple[bool, str]:
    """Send an email; return (success, user-facing message).

    Why:
    - Email is an external dependency; failures should not crash the app.
    - Debug mode can surface more details without exposing them to normal users.
    """
    msg = EmailMessage()
    msg["Subject"] = subject
    msg["From"] = config.from_email
    msg["To"] = to_email
    msg.set_content(body)

    try:
        with smtplib.SMTP(config.smtp_server, config.smtp_port, timeout=10) as smtp:
            smtp.ehlo()
            smtp.starttls()
            smtp.ehlo()
            smtp.login(config.smtp_username, config.smtp_password)
            smtp.send_message(msg)
        return True, "Email sent successfully."
    except Exception as exc:
        logger.exception("Email sending failed")
        if config.debug:
            return False, f"Email could not be sent: {exc}"
        return False, "Email could not be sent due to a technical issue."


def send_admin_report_email(subject: str, body: str, *, config: AppConfig) -> tuple[bool, str]:
    """Send report email to the admin inbox only (keeps reporting separate from user emails)."""
    if not config.admin_inbox:
        return False, "ADMIN_INBOX is not configured."

    msg = EmailMessage()
    msg["Subject"] = subject
    msg["From"] = config.from_email
    msg["To"] = config.admin_inbox
    msg.set_content(body)

    try:
        with smtplib.SMTP(config.smtp_server, config.smtp_port, timeout=10) as smtp:
            smtp.ehlo()
            smtp.starttls()
            smtp.ehlo()
            smtp.login(config.smtp_username, config.smtp_password)
            smtp.send_message(msg, to_addrs=[config.admin_inbox])
        return True, "Report email sent successfully."
    except Exception as exc:
        logger.exception("Report email sending failed")
        if config.debug:
            return False, f"Report email could not be sent: {exc}"
        return False, "Report email could not be sent due to a technical issue."


def confirmation_email_text(recipient_name: str, importance: str) -> tuple[str, str]:
    """Build the confirmation email for a newly created issue."""
    subject = "Reporting Tool @ HSG: Issue Received"
    sla_hours = SLA_HOURS_BY_IMPORTANCE.get(importance)

    sla_text = (
        f"Expected handling time (SLA): within {sla_hours} hours."
        if sla_hours is not None
        else "Expected handling time (SLA): n/a."
    )

    body = f"""Dear {recipient_name},

Thank you for contacting us regarding your concern. We hereby confirm that we have received your issue report and that it is currently under review by the responsible team.

{sla_text}

We will keep you informed about the progress and notify you once the matter has been resolved.

Kind regards,
HSG Service Team
"""
    return subject, body


def resolved_email_text(recipient_name: str) -> tuple[str, str]:
    """Build the email sent when an issue is marked resolved."""
    subject = "Reporting Tool @ HSG: Issue Resolved"
    body = f"""Hello {recipient_name},

We are pleased to inform you that the issue you reported via the Reporting Tool @ HSG has been resolved.

Kind regards,
HSG Service Team
"""
    return subject, body


# ============================================================================
# REPORTING FUNCTIONS
# ============================================================================
def build_weekly_report(df_all: pd.DataFrame) -> tuple[str, str]:
    """Build a concise summary report from all issues (last 7 days)."""
    now_dt = now_zurich()
    since_dt = now_dt - timedelta(days=7)

    df = df_all.copy()
    df["created_at_dt"] = parse_iso_series_to_zurich(df["created_at"])
    df["resolved_at_dt"] = parse_iso_series_to_zurich(df["resolved_at"])

    new_last_7d = df[df["created_at_dt"] >= since_dt]
    resolved_last_7d = df[(df["resolved_at_dt"].notna()) & (df["resolved_at_dt"] >= since_dt)]
    open_issues = df[df["status"] != "Resolved"]

    subject = f"Reporting Tool ‚Äì Weekly Summary ({now_dt.strftime('%Y-%m-%d')})"
    body = (
        "Weekly summary (last 7 days):\n"
        f"- New issues: {len(new_last_7d)}\n"
        f"- Resolved issues: {len(resolved_last_7d)}\n"
        f"- Open issues (current): {len(open_issues)}\n\n"
        "Top issue types (open):\n"
    )

    if not open_issues.empty:
        top_types = open_issues["issue_type"].value_counts().head(5)
        for issue_type, count in top_types.items():
            body += f"- {issue_type}: {count}\n"
    else:
        body += "- n/a\n"

    body += "\nThis email was generated by the Reporting Tool @ HSG."
    return subject, body


def send_weekly_report_if_due(con: sqlite3.Connection, *, config: AppConfig) -> None:
    """Send a weekly report once at the configured weekday/hour (idempotent on reruns)."""
    if not config.auto_weekly_report:
        return

    now_dt = now_zurich()
    if now_dt.weekday() != config.report_weekday or now_dt.hour != config.report_hour:
        return

    # Deduplicate: reruns during the same hour/day should not spam emails.
    log_df = fetch_report_log(con, "weekly")
    if not log_df.empty:
        last_sent = iso_to_dt(str(log_df.iloc[0]["sent_at"]))
        if last_sent is not None and last_sent.date() == now_dt.date():
            return

    df_all = fetch_submissions(con)
    subject, body = build_weekly_report(df_all)
    ok, _ = send_admin_report_email(subject, body, config=config)
    if ok:
        mark_report_sent(con, "weekly")


# ============================================================================
# UI HELPER FUNCTIONS
# ============================================================================
def show_errors(errors: Iterable[str]) -> None:
    """Display validation errors in a clear, actionable way.

    Why:
    - Users need fast feedback + concrete next steps.
    - A consistent error block improves UX and grading clarity.
    """
    errors_list = [e for e in errors if str(e).strip()]
    if not errors_list:
        return

    with bordered_container(key="error_box"):
        st.error("‚ùå Please fix the following issues:")
        for i, err in enumerate(errors_list, 1):
            st.markdown(f"**{i}.** {err}")

        st.divider()

        # Optional helper: allows users to quickly reset the most error-prone fields.
        if st.button("üîÑ Clear form fields", key="clear_form_fields", type="secondary", use_container_width=True):
            for key in ["issue_name", "issue_email", "issue_room", "issue_description", "issue_photo"]:
                st.session_state.pop(key, None)
            st.rerun()


def show_logo() -> None:
    """Show logo but do not fail if the asset is missing (keeps grading runnable)."""
    try:
        st.sidebar.image(LOGO_PATH, width=170, use_container_width=False)
    except FileNotFoundError:
        st.sidebar.warning("Logo image not found. Ensure the logo file is in the repository root.")

def show_empty_state(icon: str, title: str, message: str) -> None:
    """Show a friendly empty state without relying on custom HTML."""
    with bordered_container(key="empty_state"):
        st.markdown(f"## {icon} {title}")
        st.caption(message)

def render_map_iframe() -> None:
    """Embed the campus map as a reference (kept in an expander to avoid UI clutter)."""
    with st.expander("üìç Campus Map Reference", expanded=False):
        st.markdown(
            f"""
            <iframe src="{MAP_IFRAME_URL}"
                width="100%" height="420" frameborder="0"
                marginheight="0" marginwidth="0" scrolling="no"></iframe>
            """,
            unsafe_allow_html=True,
        )

def location_label(loc_id: str) -> str:
    """Convert internal location IDs into user-friendly labels.

    Why:
    - If the mapping is incomplete, showing the raw ID helps debugging/grading.
    """
    loc_id = str(loc_id)
    if loc_id in LOCATIONS:
        return LOCATIONS[loc_id]["label"]
    return f"Unknown location ({loc_id})"

def asset_display_label(row: pd.Series) -> str:
    """Build a descriptive dropdown label so users can decide quickly."""
    status = str(row.get("status", "")).strip().lower()
    if status == "available":
        status_text = "‚úÖ Available"
    elif status == "booked":
        status_text = "‚õî Booked"
    else:
        status_text = str(row.get("status", ""))

    loc = location_label(str(row.get("location_id", "")))
    return f'{row.get("asset_name", "")} ‚Ä¢ {row.get("asset_type", "")} ‚Ä¢ {loc} ‚Ä¢ {status_text}'


def format_booking_table(df: pd.DataFrame) -> pd.DataFrame:
    """Format booking data for display (stable date/time formatting)."""
    if df.empty:
        return df

    out = df.copy()
    out["start_time"] = parse_iso_series_to_zurich(out["start_time"])
    out["end_time"] = parse_iso_series_to_zurich(out["end_time"])
    out = out.dropna(subset=["start_time", "end_time"]).sort_values(by=["start_time"])
    out["start_time"] = out["start_time"].dt.strftime("%Y-%m-%d %H:%M")
    out["end_time"] = out["end_time"].dt.strftime("%Y-%m-%d %H:%M")

    return out.rename(columns={"user_name": "User", "start_time": "Start Time", "end_time": "End Time"})


def format_user_bookings_table(df: pd.DataFrame) -> pd.DataFrame:
    """Format a user‚Äôs bookings (same formatting as the asset booking table)."""
    if df.empty:
        return df

    out = df.copy()
    out["start_time"] = parse_iso_series_to_zurich(out["start_time"])
    out["end_time"] = parse_iso_series_to_zurich(out["end_time"])

    out = out.dropna(subset=["start_time", "end_time"]).sort_values(by=["start_time"])
    out["start_time"] = out["start_time"].dt.strftime("%Y-%m-%d %H:%M")
    out["end_time"] = out["end_time"].dt.strftime("%Y-%m-%d %H:%M")

    return out.rename(
        columns={
            "asset_id": "Asset ID",
            "asset_name": "Asset",
            "asset_type": "Type",
            "start_time": "Start",
            "end_time": "End",
        }
    )


def truncate_text(value: str, max_chars: int = DESCRIPTION_PREVIEW_CHARS) -> str:
    """Shorten long text for tables while keeping detail available elsewhere."""
    text = (value or "").strip()
    if len(text) <= max_chars:
        return text
    return text[: max_chars - 1] + "‚Ä¶"

def bordered_container(*, key: str) -> st.delta_generator.DeltaGenerator:
    """Create a visually grouped container.

    Compatibility note:
    - Some Streamlit versions don't support `border=` and/or `key=` on containers.
    - We keep the function signature stable (key stays), but we don't pass it to st.container.
    """
    try:
        return st.container(border=True)
    except TypeError:
        return st.container()


# ============================================================================
# APPLICATION PAGES
# ============================================================================
def page_submission_form(con: sqlite3.Connection, *, config: AppConfig) -> None:
    """User-facing issue submission flow (UI intentionally kept simple)."""
    st.header("üìù Report a Facility Issue")

    if st.session_state.pop("issue_submit_success_toast", False):
        # Toast after successful submit (shown on next rerun)
        details = st.session_state.pop("issue_submit_success_details", None)
        if details:
            st.toast(
                f"Issue #{details['id']} reported ‚úÖ ‚Ä¢ {details['room']} ‚Ä¢ {details['priority']}",
                icon="üìù",
            )
        else:
            st.toast("Issue reported successfully ‚úÖ", icon="üìù")

    st.caption("Fields marked with * are mandatory.")

    # Defaults are set once so reruns remain deterministic (avoids KeyErrors on session_state).
    st.session_state.setdefault("issue_name", "")
    st.session_state.setdefault("issue_email", "")
    st.session_state.setdefault("issue_room", "")
    st.session_state.setdefault("issue_type", ISSUE_TYPES[0])
    st.session_state.setdefault("issue_priority", "Low")
    st.session_state.setdefault("issue_description", "")

    email_raw = ""
    room_raw = ""
    submitted = False

    with bordered_container(key="issue_form_card"):
        with st.form("issue_submit_form", clear_on_submit=False):
            st.subheader("üë§ Your Information")
            c1, c2 = st.columns(2)
    
            with c1:
                st.text_input("Name*", placeholder="e.g., Max Muster", key="issue_name")
    
            with c2:
                email_raw = (
                    st.text_input(
                        "Email Address*",
                        placeholder="firstname.lastname@student.unisg.ch",
                        key="issue_email",
                        help=HELP_TEXTS["email"],
                    )
                    .strip()
                    .lower()
                )
                if email_raw and not valid_email(email_raw):
                    st.warning("Please use ‚Ä¶@unisg.ch or ‚Ä¶@student.unisg.ch.", icon="‚ö†Ô∏è")
    
            st.subheader("üìã Issue Details")
            c3, c4 = st.columns(2)
    
            with c3:
                room_raw = st.text_input(
                    "Room Number*",
                    placeholder="e.g., A 09-001",
                    key="issue_room",
                    help=HELP_TEXTS["room"],
                ).strip()
    
                if room_raw:
                    normalized = normalize_room(room_raw)
                    if normalized != room_raw:
                        st.caption(f"Saved as: **{normalized}**")
                    if not valid_room_number(normalized):
                        st.warning("Format example: **A 09-001** (letter + space + 09-001).", icon="‚ö†Ô∏è")
    
            with c4:
                st.selectbox("Issue Type*", ISSUE_TYPES, key="issue_type")
    
            # FULL WIDTH priority (wie du wolltest)
            st.selectbox(
                "Priority Level*",
                options=IMPORTANCE_LEVELS,
                key="issue_priority",
                help=HELP_TEXTS["priority"],
            )
    
            sla_hours = SLA_HOURS_BY_IMPORTANCE.get(str(st.session_state.get("issue_priority", "")))
            if sla_hours is not None:
                target_dt = now_zurich() + timedelta(hours=int(sla_hours))
                st.info(
                    f"‚è±Ô∏è **Target handling time:** within **{sla_hours} hours** "
                    f"(approx. if submitted now: **{target_dt.strftime('%a, %d %b %Y %H:%M')}**).",
                    icon="‚ÑπÔ∏è",
                )
                st.caption("SLA = Service Level Agreement (service target time).")
            else:
                st.info("‚è±Ô∏è **Target handling time:** n/a.", icon="‚ÑπÔ∏è")
    
            st.text_area(
                "Problem Description*",
                max_chars=MAX_ISSUE_DESCRIPTION_CHARS,
                placeholder="What happened? Where exactly? Since when? Any impact?",
                height=110,
                key="issue_description",
                help=HELP_TEXTS["description"],
            )
    
            st.subheader("üì∏ Upload Photo")
            uploaded_file = st.file_uploader(
                "Optional: add a photo (jpg / png)",
                type=["jpg", "jpeg", "png"],
                help="Avoid personal data in the photo where possible.",
                key="issue_photo",
            )
            if uploaded_file is not None:
                st.image(uploaded_file, caption="Preview", use_container_width=True)
    
            render_map_iframe()
    
            with st.expander("üîé Review your report", expanded=False):
                st.write(f"**Name:** {st.session_state.get('issue_name', '')}")
                st.write(f"**Email:** {st.session_state.get('issue_email', '')}")
                st.write(f"**Room:** {normalize_room(st.session_state.get('issue_room', ''))}")
                st.write(f"**Issue Type:** {st.session_state.get('issue_type', '')}")
                st.write(f"**Priority:** {st.session_state.get('issue_priority', '')}")
    
            # SUBMIT ganz unten + full width
            submitted = st.form_submit_button("üöÄ Submit Issue Report", type="primary", use_container_width=True)
    
    if not submitted:
        return

    # Submit handling (DB + email) stays the same
    sub = Submission(
        name=str(st.session_state["issue_name"]).strip(),
        hsg_email=str(st.session_state["issue_email"]).strip().lower(),
        issue_type=str(st.session_state["issue_type"]),
        room_number=normalize_room(str(st.session_state["issue_room"])),
        importance=str(st.session_state["issue_priority"]),
        user_comment=str(st.session_state["issue_description"]).strip(),
    )

    errors = validate_submission_input(sub)
    if errors:
        show_errors(errors)
        return

    try:
        submission_id = insert_submission(con, sub)
    except Exception as e:
        st.error("Database error while saving your report. Please try again.")
        logger.error("Failed to insert submission: %s", e)
        return

    subject, body = confirmation_email_text(sub.name.strip(), sub.importance)
    ok, msg = send_email(sub.hsg_email, subject, body, config=config)

    sla_hours = SLA_HOURS_BY_IMPORTANCE.get(sub.importance)
    submitted_at = now_zurich().strftime("%Y-%m-%d %H:%M")

    st.success("‚úÖ Issue reported successfully!")
    st.info(
        f"**Details:**\n"
        f"- **Reference ID:** #{submission_id}\n"
        f"- **Room:** {normalize_room(sub.room_number)}\n"
        f"- **Priority:** {sub.importance} ({sla_hours if sla_hours is not None else 'N/A'}h SLA)\n"
        f"- **Status:** Pending\n"
        f"- **Submitted:** {submitted_at}"
    )

    if ok:
        st.toast("Confirmation email sent!", icon="üìß")
    else:
        st.warning(f"Note: Email notification failed: {msg}")

    for k in [
        "issue_name",
        "issue_email",
        "issue_room",
        "issue_type",
        "issue_priority",
        "issue_description",
        "issue_photo",
    ]:
        st.session_state.pop(k, None)

    st.session_state["issue_submit_success_details"] = {
        "id": submission_id,
        "room": normalize_room(sub.room_number),
        "priority": sub.importance,
    }
    st.session_state["issue_submit_success_toast"] = True
    st.rerun()

def build_display_table(df: pd.DataFrame) -> pd.DataFrame:
    """Prepare a user-friendly DataFrame for the dashboard table."""
    display_df = df.copy()
    display_df["user_comment_preview"] = display_df["user_comment"].astype(str).apply(truncate_text)

    display_df = display_df.rename(
        columns={
            "id": "ID",
            "name": "Reporter Name",
            "hsg_email": "Email",
            "issue_type": "Issue Type",
            "room_number": "Room Number",
            "importance": "Priority",
            "status": "Status",
            "user_comment_preview": "Description",
            "created_at": "Submitted",
            "updated_at": "Last Updated",
            "assigned_to": "Assigned To",
            "resolved_at": "Resolved At",
            "expected_resolved_at": "SLA Target",
        }
    )

    # Sort by priority first so high-impact issues surface immediately.
    importance_order = {"High": 0, "Medium": 1, "Low": 2}
    display_df["_priority_rank"] = display_df["Priority"].map(importance_order).fillna(99).astype(int)

    display_df = display_df.sort_values(by=["_priority_rank", "Submitted"], ascending=[True, False]).drop(
        columns=["_priority_rank"]
    )

    # Keep the full comment accessible in the details view; table uses a preview.
    display_df = display_df.drop(columns=["user_comment"], errors="ignore")
    return display_df


def render_charts(df: pd.DataFrame) -> None:
    """Render simple charts for quick insights (kept lightweight for Streamlit reruns)."""
    if df.empty:
        st.info("No data available for charts.")
        return

    df_local = df.copy()
    df_local["created_at_dt"] = parse_iso_series_to_zurich(df_local["created_at"])

    tab1, tab2, tab3, tab4 = st.tabs(
        ["üìä Issue Types", "üìÖ Daily Trends", "üéØ Priority Levels", "üìà Status Distribution"]
    )

    with tab1:
        st.subheader("Issues by Type")
        issue_counts = df_local["issue_type"].value_counts().reindex(ISSUE_TYPES, fill_value=0)
        st.bar_chart(issue_counts)

    with tab2:
        st.subheader("Submission Trends")
        df_dates = df_local.dropna(subset=["created_at_dt"]).copy()
        if df_dates.empty:
            st.info("No valid submission dates available.")
        else:
            df_dates["date"] = df_dates["created_at_dt"].dt.date
            daily_counts = df_dates.groupby("date").size()
            st.line_chart(daily_counts)

    with tab3:
        st.subheader("Priority Distribution")
        imp_counts = df_local["importance"].value_counts().reindex(IMPORTANCE_LEVELS, fill_value=0)
        st.bar_chart(imp_counts)

    with tab4:
        st.subheader("Status Overview")
        status_counts = df_local["status"].value_counts().reindex(STATUS_LEVELS, fill_value=0)
        st.bar_chart(status_counts)


def page_submitted_issues(con: sqlite3.Connection) -> None:
    """Dashboard view for submitted issues (filters + details + export)."""
    st.header("üìã Submitted Issues Dashboard")

    try:
        with st.spinner("üìä Loading issues..."):
            df = fetch_submissions(con)
    except Exception as e:
        st.error(f"Failed to load submissions: {e}")
        logger.error("Database error in submitted issues: %s", e)
        return

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Issues", len(df))
    with col2:
        open_count = len(df[df["status"] != "Resolved"]) if not df.empty else 0
        st.metric("Open Issues", open_count)
    with col3:
        resolved_count = len(df[df["status"] == "Resolved"]) if not df.empty else 0
        st.metric("Resolved", resolved_count)
    with col4:
        high_priority = len(df[df["importance"] == "High"]) if not df.empty else 0
        st.metric("High Priority", high_priority)

    if df.empty:
        show_empty_state("üì≠", "No Issues Found", "No issues have been submitted yet.")
        return

    st.subheader("üîç Filter Options")
    col_filter1, col_filter2, col_filter3 = st.columns([1, 1, 1])

    with col_filter1:
        status_filter = st.multiselect(
            "Status",
            options=STATUS_LEVELS,
            default=STATUS_LEVELS,
            help="Select statuses to display",
        )

    with col_filter2:
        importance_filter = st.multiselect(
            "Priority",
            options=IMPORTANCE_LEVELS,
            default=IMPORTANCE_LEVELS,
            help="Select priority levels to display",
        )

    with col_filter3:
        issue_type_filter = st.multiselect(
            "Issue Type",
            options=ISSUE_TYPES,
            default=ISSUE_TYPES,
            help="Select issue types to display",
        )

    col_filter4, col_filter5 = st.columns([1, 2])
    with col_filter4:
        open_only = st.toggle(
            "Open issues only",
            value=False,
            help="When enabled, hides resolved issues regardless of Status filter.",
        )

    with col_filter5:
        date_range_label_to_days = {
            "Last 7 days": 7,
            "Last 30 days": 30,
            "Last 90 days": 90,
            "All time": None,
        }
        date_range_choice = st.selectbox(
            "Date range (by submitted date)",
            options=list(date_range_label_to_days.keys()),
            index=1,
        )

    filtered_df = df[
        df["status"].isin(status_filter)
        & df["importance"].isin(importance_filter)
        & df["issue_type"].isin(issue_type_filter)
    ].copy()

    if open_only:
        filtered_df = filtered_df[filtered_df["status"] != "Resolved"].copy()

    days = date_range_label_to_days[date_range_choice]
    if days is not None:
        cutoff = now_zurich() - timedelta(days=int(days))
        filtered_df["created_at_dt"] = parse_iso_series_to_zurich(filtered_df["created_at"])
        filtered_df = filtered_df[filtered_df["created_at_dt"].notna() & (filtered_df["created_at_dt"] >= cutoff)].copy()
        filtered_df = filtered_df.drop(columns=["created_at_dt"], errors="ignore")

    if filtered_df.empty:
        st.info("No issues match the selected filters.")
        return

    def _sla_target_row(r: pd.Series) -> datetime | None:
        return expected_resolution_dt(str(r.get("created_at", "")), str(r.get("importance", "")))

    filtered_df["expected_resolved_at"] = filtered_df.apply(_sla_target_row, axis=1)

    # Optional KPI: only computed when the required columns exist and parse cleanly.
    resolved_df = filtered_df[filtered_df["status"] == "Resolved"].copy()
    if not resolved_df.empty and "created_at" in resolved_df.columns and "resolved_at" in resolved_df.columns:
        resolved_df["created_at_dt"] = parse_iso_series_to_zurich(resolved_df["created_at"])
        resolved_df["resolved_at_dt"] = parse_iso_series_to_zurich(resolved_df["resolved_at"])
        resolved_df = resolved_df.dropna(subset=["created_at_dt", "resolved_at_dt"])
        if not resolved_df.empty:
            resolved_df["resolution_hours"] = (
                (resolved_df["resolved_at_dt"] - resolved_df["created_at_dt"]).dt.total_seconds() / 3600.0
            )
            avg_resolution = resolved_df["resolution_hours"].mean()
            st.metric("Average Resolution Time", f"{avg_resolution:.1f} hours")

    st.subheader("üßæ Quick Issue Details")
    issue_ids = filtered_df["id"].astype(int).tolist()
    selected_issue_id = st.selectbox(
        "Select an issue to view full details:",
        options=issue_ids,
        index=0,
        format_func=lambda i: f"#{i}",
    )
    selected_row = filtered_df[filtered_df["id"].astype(int) == int(selected_issue_id)].iloc[0]

    with st.expander("View full details", expanded=True):
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.write("**Issue Type:**", selected_row.get("issue_type", ""))
            st.write("**Room:**", selected_row.get("room_number", ""))
        with col_b:
            st.write("**Priority:**", selected_row.get("importance", ""))
            st.write("**Status:**", selected_row.get("status", ""))
        with col_c:
            st.write("**Assigned To:**", selected_row.get("assigned_to", "Unassigned") or "Unassigned")
            st.write("**Submitted:**", selected_row.get("created_at", ""))

        st.divider()
        st.write("**Reporter:**", selected_row.get("name", ""))
        st.write("**Email:**", selected_row.get("hsg_email", ""))
        st.write("**Description:**")
        st.write(selected_row.get("user_comment", ""))

    st.subheader(f"üìä Results ({len(filtered_df)} issues)")

    open_first = st.toggle("Show open issues first", value=True)

    if open_first:
        filtered_df["_open_rank"] = (filtered_df["status"] == "Resolved").astype(int)  # open=0, resolved=1
        filtered_df = filtered_df.sort_values(by=["_open_rank", "importance", "created_at"], ascending=[True, True, False])
        filtered_df = filtered_df.drop(columns=["_open_rank"], errors="ignore")

    display_df = build_display_table(filtered_df)

    column_config = {
        "ID": st.column_config.NumberColumn("ID", help="Unique issue identifier"),
        "Submitted": st.column_config.DatetimeColumn("Submitted", help="When the issue was submitted"),
        "Last Updated": st.column_config.DatetimeColumn("Last Updated", help="Last status/assignment update"),
        "Resolved At": st.column_config.DatetimeColumn("Resolved At", help="When the issue was marked resolved"),
        "SLA Target": st.column_config.DatetimeColumn("SLA Target", help="Expected resolution time based on SLA"),
        "Description": st.column_config.TextColumn(
            "Description",
            help="Preview only. Use 'Quick Issue Details' to read the full description.",
            width="large",
        ),
    }

    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True,
        height=420,
        column_config=column_config,
    )

    st.subheader("üíæ Export")
    col_export1, col_export2 = st.columns(2)

    with col_export1:
        csv_bytes = filtered_df.to_csv(index=False).encode("utf-8")
        st.download_button(
            "Download CSV",
            data=csv_bytes,
            file_name=f"issues_{now_zurich().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            use_container_width=True,
        )

    with col_export2:
        if st.button("Refresh", use_container_width=True):
            st.rerun()

    st.subheader("üìà Visualizations")
    render_charts(filtered_df)

    with st.expander("üìã Status Change History"):
        try:
            log_df = fetch_status_log(con)
            if log_df.empty:
                st.info("No status changes recorded yet.")
            else:
                st.dataframe(log_df, use_container_width=True, hide_index=True)
        except Exception as e:
            st.error(f"Failed to load audit log: {e}")


def page_booking(con: sqlite3.Connection) -> None:
    """Booking UI with availability checks and a transparent booking overview."""
    st.header("üìÖ Book an Asset")

    # Toasts are stored in session_state so the user sees a confirmation after rerun.
    if st.session_state.pop("booking_success_toast", False):
        details = st.session_state.pop("booking_success_details", None)
        if details:
            st.toast(
                f"Booked {details['asset_name']} ‚Ä¢ {details['start']} ‚Üí {details['end']} ‚úÖ",
                icon="üìÖ",
            )
        else:
            st.toast("Booking confirmed ‚úÖ", icon="üìÖ")

    try:
        sync_asset_statuses_from_bookings(con)
        assets_df = fetch_assets(con)
    except Exception as e:
        st.error(f"Failed to load assets: {e}")
        logger.error("Database error in booking page: %s", e)
        return

    if assets_df.empty:
        st.warning("No assets available for booking.")
        return

    st.subheader("üìä Booking Overview")

    try:
        total_assets = len(assets_df)
        available_assets = int((assets_df["status"].astype(str).str.lower() == "available").sum())
        booked_assets = int((assets_df["status"].astype(str).str.lower() == "booked").sum())
        active_bookings = count_active_bookings(con)
        future_bookings = count_future_bookings(con)
    except Exception as e:
        st.error(f"Failed to compute booking metrics: {e}")
        logger.error("Booking metrics error: %s", e)
        total_assets, available_assets, booked_assets, active_bookings, future_bookings = 0, 0, 0, 0, 0

    k1, k2, k3, k4, k5 = st.columns(5)
    k1.metric("Total Assets", total_assets)
    k2.metric("Available", available_assets)
    k3.metric("Booked", booked_assets)
    k4.metric("Active Bookings", active_bookings)
    k5.metric("Future Bookings", future_bookings)

    st.subheader("üîç Find Assets")

    col_search1, col_search2, col_search3 = st.columns([2, 1, 1])
    with col_search1:
        search_term = st.text_input(
            "Search",
            placeholder="e.g., projector, meeting room, chair...",
            help="Search by asset name, type, or location",
        ).strip().lower()

    with col_search2:
        type_filter = st.selectbox(
            "Asset Type",
            options=["All Types"] + sorted(assets_df["asset_type"].unique().tolist()),
        )

    with col_search3:
        availability_filter = st.selectbox(
            "Availability",
            options=["All", "Available Only", "Booked Only"],
        )

    view_df = assets_df.copy()
    view_df["location_label"] = view_df["location_id"].apply(location_label)
    view_df["display_label"] = view_df.apply(asset_display_label, axis=1)

    if type_filter != "All Types":
        view_df = view_df[view_df["asset_type"] == type_filter]

    if availability_filter == "Available Only":
        view_df = view_df[view_df["status"].astype(str).str.lower() == "available"]
    elif availability_filter == "Booked Only":
        view_df = view_df[view_df["status"].astype(str).str.lower() == "booked"]

    if search_term:
        mask = (
            view_df["asset_name"].str.lower().str.contains(search_term, na=False)
            | view_df["asset_type"].str.lower().str.contains(search_term, na=False)
            | view_df["location_label"].str.lower().str.contains(search_term, na=False)
        )
        view_df = view_df[mask].copy()

    # Prefer showing available assets first to reduce user friction.
    view_df["_status_rank"] = (
        view_df["status"].astype(str).str.lower().map({"available": 0, "booked": 1}).fillna(99).astype(int)
    )
    view_df = view_df.sort_values(by=["_status_rank", "asset_type", "asset_name"]).drop(columns=["_status_rank"])

    if view_df.empty:
        st.info("No assets match your filters/search. Try 'All Types' + 'All', or use a shorter keyword.")
        return

    st.subheader("üéØ Select Asset")
    asset_labels = {str(r["asset_id"]): str(r["display_label"]) for _, r in view_df.iterrows()}

    default_asset_id = st.session_state.get("booking_asset_id")
    if default_asset_id not in asset_labels:
        default_asset_id = list(asset_labels.keys())[0]

    asset_id = st.selectbox(
        "Choose asset:",
        options=list(asset_labels.keys()),
        index=list(asset_labels.keys()).index(default_asset_id),
        format_func=lambda aid: asset_labels[aid],
    )
    st.session_state["booking_asset_id"] = asset_id

    selected_asset = assets_df[assets_df["asset_id"] == asset_id].iloc[0]

    st.subheader("üìã Asset Details")
    col_details1, col_details2, col_details3 = st.columns(3)
    with col_details1:
        st.metric("Status", str(selected_asset["status"]).capitalize())
    with col_details2:
        st.metric("Type", selected_asset["asset_type"])
    with col_details3:
        st.metric("Location", location_label(str(selected_asset["location_id"])))

    if str(selected_asset["status"]).lower() == "available":
        st.success("‚úÖ This asset is available for booking.")
    else:
        next_free = next_available_time(con, asset_id)
        if next_free:
            st.warning(f"‚õî Currently booked. Next available: **{next_free.strftime('%Y-%m-%d %H:%M')}**")
        else:
            st.warning("‚õî Currently booked. No future bookings found.")

    st.subheader("üìÖ Upcoming Bookings")
    try:
        future_bookings = fetch_future_bookings(con, asset_id)
        if future_bookings.empty:
            st.info("No upcoming bookings scheduled.")
        else:
            st.dataframe(format_booking_table(future_bookings), use_container_width=True, hide_index=True)
    except Exception as e:
        st.error(f"Failed to load bookings: {e}")

    st.divider()
    st.subheader("üë§ My Bookings")

    my_name = st.text_input(
        "Enter your name to view your upcoming bookings",
        placeholder="e.g., Max Muster",
        key="my_bookings_name",
    ).strip()

    if not my_name:
        st.caption("Tip: Use the exact same name you used when booking.")
    else:
        try:
            my_df = fetch_future_bookings_for_user(con, my_name)
            if my_df.empty:
                st.info("No upcoming bookings found for this name.")
            else:
                st.dataframe(format_user_bookings_table(my_df), use_container_width=True, hide_index=True)

                csv_bytes = my_df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    "Download my bookings (CSV)",
                    data=csv_bytes,
                    file_name=f"my_bookings_{now_zurich().strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    use_container_width=True,
                )
        except Exception as e:
            st.error(f"Failed to load your bookings: {e}")
            logger.error("My bookings load error: %s", e)

    if str(selected_asset["status"]).lower() != "available":
        st.info("Select an available asset to create a booking.")
        return

    st.divider()
    st.subheader("üìù Create New Booking")

    with st.form("booking_form"):
        user_name = st.text_input("Your Name*", placeholder="e.g., Max Muster").strip()

        col_time1, col_time2, col_time3 = st.columns(3)
        with col_time1:
            start_date = st.date_input(
                "Start Date*",
                value=now_zurich().date(),
                min_value=now_zurich().date(),
            )

        with col_time2:
            current_time = now_zurich().time()
            rounded_minute = 30 * ((current_time.minute + 14) // 30)
            if rounded_minute == 60:
                default_time = current_time.replace(
                    hour=min(current_time.hour + 1, 23),
                    minute=0,
                    second=0,
                    microsecond=0,
                )
            else:
                default_time = current_time.replace(minute=rounded_minute, second=0, microsecond=0)

            start_time = st.time_input(
                "Start Time*",
                value=default_time,
                step=1800,
                help="30-minute intervals",
            )

        with col_time3:
            duration_options = {"1 hour": 1, "2 hours": 2, "3 hours": 3, "4 hours": 4, "6 hours": 6, "8 hours": 8}
            duration_choice = st.selectbox("Duration*", options=list(duration_options.keys()))
            duration_hours = duration_options[duration_choice]

        start_dt = safe_localize(datetime.combine(start_date, start_time))
        end_dt = start_dt + timedelta(hours=duration_hours)

        if start_dt < now_zurich():
            st.warning("Selected start time is in the past. Please choose a later time.")

        st.info(
            f"**Booking Summary:**\n"
            f"- **Asset:** {selected_asset['asset_name']}\n"
            f"- **Date:** {start_dt.strftime('%A, %d %B %Y')}\n"
            f"- **Time:** {start_dt.strftime('%H:%M')} ‚Üí {end_dt.strftime('%H:%M')}\n"
            f"- **Duration:** {duration_hours} hour{'s' if duration_hours > 1 else ''}"
        )

        submitted = st.form_submit_button("‚úÖ Confirm Booking", type="primary", use_container_width=True)

    if not submitted:
        return

    if not user_name:
        st.error("Please enter your name.")
        return

    if start_dt < now_zurich():
        st.error("Start time cannot be in the past.")
        return

    if end_dt <= start_dt:
        st.error("End time must be after start time.")
        return

    try:
        if not is_asset_available(con, asset_id, start_dt, end_dt):
            st.error("This asset is already booked during the selected time period.")
            return
    except Exception as e:
        st.error(f"Availability check failed: {e}")
        logger.error("Availability check error: %s", e)
        return

    try:
        with con:
            con.execute(
                """
                INSERT INTO bookings (asset_id, user_name, start_time, end_time, created_at)
                VALUES (?, ?, ?, ?, ?)
                """,
                (
                    asset_id,
                    user_name,
                    start_dt.isoformat(timespec="seconds"),
                    end_dt.isoformat(timespec="seconds"),
                    now_zurich_str(),
                ),
            )

        sync_asset_statuses_from_bookings(con)

        st.session_state["booking_success_details"] = {
            "asset_name": str(selected_asset["asset_name"]),
            "start": start_dt.strftime("%Y-%m-%d %H:%M"),
            "end": end_dt.strftime("%Y-%m-%d %H:%M"),
        }
        st.session_state["booking_success_toast"] = True
        st.rerun()

    except Exception as e:
        st.error(f"Failed to create booking: {e}")
        logger.error("Booking creation error: %s", e)


def page_assets(con: sqlite3.Connection) -> None:
    """Asset tracking page (filter/search + move assets)."""
    st.header("üìç Asset Tracking")
    if st.session_state.pop("asset_move_success_toast", False):
        st.toast("Asset moved ‚úÖ", icon="üöö")

    try:
        df = fetch_assets(con)
    except Exception as e:
        st.error(f"Failed to load assets: {e}")
        logger.error("Database error in asset tracking: %s", e)
        return

    if df.empty:
        show_empty_state("üì¶", "No Assets Found", "No assets available in the system.")
        return

    st.subheader("üìä Asset Overview")

    total_assets = len(df)
    available_assets = int((df["status"].astype(str).str.lower() == "available").sum())
    booked_assets = int((df["status"].astype(str).str.lower() == "booked").sum())

    k1, k2, k3 = st.columns(3)
    k1.metric("Total Assets", total_assets)
    k2.metric("Available", available_assets)
    k3.metric("Booked", booked_assets)

    df = df.copy()
    df["location_label"] = df["location_id"].apply(location_label)

    st.subheader("üîç Filter Assets")
    col_filter1, col_filter2 = st.columns(2)

    with col_filter1:
        location_filter = st.multiselect(
            "Location",
            options=sorted(df["location_label"].unique()),
            default=sorted(df["location_label"].unique()),
        )

    with col_filter2:
        status_filter = st.multiselect(
            "Status",
            options=sorted(df["status"].unique()),
            default=sorted(df["status"].unique()),
        )

    filtered_df = df[(df["location_label"].isin(location_filter)) & (df["status"].isin(status_filter))]

    st.subheader("üîé Search Assets")

    search_query = st.text_input(
        "Search by ID, name, or type",
        placeholder="e.g., projector, chair, laptop cart, ROOM_A_08005 ...",
    ).strip().lower()

    if search_query:
        filtered_df = filtered_df[
            filtered_df["asset_id"].astype(str).str.lower().str.contains(search_query, na=False)
            | filtered_df["asset_name"].astype(str).str.lower().str.contains(search_query, na=False)
            | filtered_df["asset_type"].astype(str).str.lower().str.contains(search_query, na=False)
        ].copy()

    location_labels = sorted(filtered_df["location_label"].unique().tolist())
    jump_location = st.selectbox("Quick jump to location", options=["(All locations)"] + location_labels)

    if jump_location != "(All locations)":
        filtered_df = filtered_df[filtered_df["location_label"] == jump_location].copy()

    st.subheader("üì¶ Assets by Location")
    if filtered_df.empty:
        st.info("No assets match the selected filters.")
    else:
        for location, group in filtered_df.groupby("location_label"):
            with st.expander(f"üè¢ {location} ({len(group)} assets)", expanded=False):
                display_data = group[["asset_id", "asset_name", "asset_type", "status"]].copy()
                display_data = display_data.rename(
                    columns={"asset_id": "ID", "asset_name": "Name", "asset_type": "Type", "status": "Status"}
                )
                st.dataframe(display_data, use_container_width=True, hide_index=True)

    st.divider()
    st.subheader("üöö Move Asset to New Location")

    assets_df = fetch_assets(con).copy()
    assets_df["location_label"] = assets_df["location_id"].apply(location_label)
    assets_df["display_label"] = assets_df.apply(asset_display_label, axis=1)

    asset_options = {str(r["asset_id"]): str(r["display_label"]) for _, r in assets_df.iterrows()}
    if not asset_options:
        st.info("No assets available for movement.")
        return

    asset_id = st.selectbox(
        "Select asset to move:",
        options=list(asset_options.keys()),
        format_func=lambda aid: asset_options[aid],
    )

    selected_asset = assets_df[assets_df["asset_id"] == asset_id].iloc[0]
    col_current1, col_current2, col_current3 = st.columns(3)
    with col_current1:
        st.metric("Current Status", str(selected_asset["status"]).capitalize())
    with col_current2:
        st.metric("Asset Type", selected_asset["asset_type"])
    with col_current3:
        st.metric("Current Location", str(selected_asset["location_label"]))

    new_location_id = st.selectbox(
        "New location:",
        options=list(LOCATIONS.keys()),
        format_func=lambda x: LOCATIONS[x]["label"],
    )

    if st.button("Move asset", type="primary", use_container_width=True):
        if new_location_id == selected_asset["location_id"]:
            st.warning("Asset is already at this location.")
        else:
            try:
                with con:
                    con.execute("UPDATE assets SET location_id = ? WHERE asset_id = ?", (new_location_id, asset_id))

                st.session_state["asset_move_success_toast"] = True
                st.rerun()
            except Exception as e:
                st.error(f"Failed to move asset: {e}")
                logger.error("Asset movement error: %s", e)


def page_overwrite_status(con: sqlite3.Connection, *, config: AppConfig) -> None:
    """Admin panel: update status/assignee and optionally notify reporter."""
    st.header("üîß Admin Panel - Issue Management")
    if st.session_state.pop("admin_update_toast", False):
        st.toast("Saved ‚úÖ", icon="‚úÖ")

    entered_password = st.text_input("Enter Admin Password", type="password")

    if not entered_password:
        st.caption("üîê Admin access required.")
        return

    if not secrets.compare_digest(entered_password, config.admin_password):
        st.error("Incorrect password.")
        return

    st.subheader("‚ö° Quick Actions")
    col_action1, col_action2 = st.columns(2)

    with col_action1:
        if st.button("Send weekly report now", use_container_width=True):
            try:
                df_all = fetch_submissions(con)
                subject, body = build_weekly_report(df_all)
                ok, msg = send_admin_report_email(subject, body, config=config)
                if ok:
                    mark_report_sent(con, "weekly")
                    st.success("Weekly report sent successfully!")
                else:
                    st.warning(f"Report sending failed: {msg}")
            except Exception as e:
                st.error(f"Failed to send report: {e}")

    with col_action2:
        if st.button("Refresh", use_container_width=True):
            st.rerun()

    try:
        df = fetch_submissions(con)
    except Exception as e:
        st.error(f"Failed to load issues: {e}")
        return

    if df.empty:
        st.info("No issues available for management.")
        return

    st.subheader("üîç Filter Issues")
    admin_status_filter = st.multiselect("Show issues with status:", options=STATUS_LEVELS, default=STATUS_LEVELS)

    filtered_df = df[df["status"].isin(admin_status_filter)]
    if filtered_df.empty:
        st.info("No issues match your filters. Try clearing filters or using a shorter search term.")
        return

    st.subheader("üéØ Select Issue to Update")
    issue_options = {
        row["id"]: f"#{row['id']}: {row['issue_type']} ({row['room_number']}) - {row['status']}"
        for _, row in filtered_df.iterrows()
    }

    selected_id = st.selectbox("Choose issue:", options=list(issue_options.keys()), format_func=lambda x: issue_options[x])
    row = df[df["id"] == selected_id].iloc[0]

    st.subheader("üìã Issue Details")
    col_details1, col_details2 = st.columns(2)
    with col_details1:
        st.metric("Issue ID", selected_id)
        st.metric("Priority", row["importance"])
        st.metric("Current Status", row["status"])
    with col_details2:
        sla_target = expected_resolution_dt(str(row["created_at"]), str(row["importance"]))
        sla_text = sla_target.strftime("%Y-%m-%d %H:%M") if sla_target else "N/A"
        st.metric("SLA Target", sla_text)
        st.metric("Assigned To", row.get("assigned_to", "Unassigned") or "Unassigned")
        st.metric("Room", row["room_number"])

    with st.expander("üìù View Full Details", expanded=False):
        st.write("**Reporter:**", row["name"])
        st.write("**Email:**", row["hsg_email"])
        st.write("**Issue Type:**", row["issue_type"])
        st.write("**Submitted:**", row["created_at"])
        st.write("**Last Updated:**", row["updated_at"])
        st.write("**Resolved At:**", row.get("resolved_at", "Not resolved"))
        st.write("**Description:**", row["user_comment"])

    st.divider()
    st.subheader("‚úèÔ∏è Update Issue")

    old_status = str(row["status"])

    with st.form("admin_update_form"):
        current_assignee = str(row.get("assigned_to", "") or "")
        assignee_options = ["(Unassigned)"] + config.assignees
        assigned_to = st.selectbox(
            "Assign to:",
            options=assignee_options,
            index=assignee_options.index(current_assignee) if current_assignee in assignee_options else 0,
        )
        assigned_to_value = None if assigned_to == "(Unassigned)" else assigned_to

        new_status = st.selectbox(
            "Update status to:",
            STATUS_LEVELS,
            index=STATUS_LEVELS.index(row["status"]) if row["status"] in STATUS_LEVELS else 0,
        )

        # Extra confirmation reduces accidental ‚ÄúResolved‚Äù clicks (important for notifications).
        confirm_resolution = True
        if old_status != "Resolved" and new_status == "Resolved":
            confirm_resolution = st.checkbox("‚úì Confirm issue resolution (will send notification email)", value=False)

        submitted = st.form_submit_button("Save changes", type="primary", use_container_width=True)

    if not submitted:
        return

    if new_status == "Resolved" and not confirm_resolution:
        st.error("Please confirm resolution before setting status to 'Resolved'.")
        return

    try:
        update_issue_admin_fields(
            con=con,
            issue_id=int(selected_id),
            new_status=new_status,
            assigned_to=assigned_to_value,
            old_status=old_status,
        )

        if old_status != "Resolved" and new_status == "Resolved":
            email_errors = validate_admin_email(str(row["hsg_email"]))
            if email_errors:
                show_errors(email_errors)
            else:
                subject, body = resolved_email_text(str(row["name"]).strip() or "there")
                ok, msg = send_email(str(row["hsg_email"]).strip(), subject, body, config=config)
                if ok:
                    st.success("‚úì Resolution notification sent to reporter.")
                else:
                    st.warning(f"Notification email failed: {msg}")

        st.session_state["admin_update_toast"] = True
        st.rerun()
    except Exception as e:
        st.error(f"Failed to update issue: {e}")
        logger.error("Admin update error: %s", e)


def page_overview_dashboard(con: sqlite3.Connection) -> None:
    """High-level overview page (quick KPIs for both issues and assets)."""
    st.header("üìä Overview Dashboard")
    st.caption("Real-time overview of system status. All times are Europe/Zurich.")

    try:
        issues = fetch_submissions(con)
        assets = fetch_assets(con)
    except Exception as e:
        st.error(f"Failed to load data: {e}")
        logger.error("Dashboard data loading error: %s", e)
        return

    st.subheader("üìà Key Metrics")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total Issues", len(issues))
    with col2:
        open_issues = len(issues[issues["status"] != "Resolved"]) if not issues.empty else 0
        st.metric("Open Issues", open_issues)
    with col3:
        resolved_issues = len(issues[issues["status"] == "Resolved"]) if not issues.empty else 0
        st.metric("Resolved Issues", resolved_issues)
    with col4:
        total_assets = len(assets)
        available_assets = len(assets[assets["status"] == "available"]) if not assets.empty else 0
        st.metric("Available Assets", f"{available_assets}/{total_assets}")

    tab1, tab2 = st.tabs(["üìã Issues Overview", "üì¶ Assets Overview"])

    with tab1:
        st.subheader("Current Issues")
        if issues.empty:
            st.info("No issues reported yet.")
        else:
            open_issues_df = issues[issues["status"] != "Resolved"]
            if not open_issues_df.empty:
                st.write(f"**Open Issues ({len(open_issues_df)}):**")
                display_open = open_issues_df[["id", "issue_type", "room_number", "importance", "status", "created_at"]].copy()
                display_open = display_open.rename(
                    columns={
                        "id": "ID",
                        "issue_type": "Type",
                        "room_number": "Room",
                        "importance": "Priority",
                        "status": "Status",
                        "created_at": "Reported",
                    }
                )
                st.dataframe(display_open, use_container_width=True, hide_index=True)
            else:
                st.success("‚úÖ All issues are resolved!")

            st.subheader("üìä Quick Statistics")
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("High Priority", len(issues[issues["importance"] == "High"]))
            with col_stat2:
                created_dt = parse_iso_series_to_zurich(issues["created_at"])
                if created_dt.notna().any():
                    avg_age_days = ((now_zurich() - created_dt).dt.total_seconds() / 86400.0).mean()
                    st.metric("Avg. Issue Age", f"{avg_age_days:.1f} days")
                else:
                    st.metric("Avg. Issue Age", "N/A")
            with col_stat3:
                top_issue = issues["issue_type"].mode()[0] if not issues.empty else "N/A"
                st.metric("Most Common Issue", top_issue)

    with tab2:
        st.subheader("Asset Inventory")
        if assets.empty:
            st.info("No assets in inventory.")
        else:
            assets_display = assets.copy()
            assets_display["location"] = assets_display["location_id"].apply(location_label)

            st.dataframe(
                assets_display[["asset_id", "asset_name", "asset_type", "status", "location"]],
                use_container_width=True,
                hide_index=True,
                column_config={
                    "asset_id": "ID",
                    "asset_name": "Name",
                    "asset_type": "Type",
                    "status": "Status",
                    "location": "Location",
                },
            )

            st.subheader("üìä Asset Statistics")
            col_asset1, col_asset2, col_asset3 = st.columns(3)
            with col_asset1:
                st.metric("Asset Types", assets["asset_type"].nunique())
            with col_asset2:
                st.metric("Currently Booked", len(assets[assets["status"] == "booked"]))
            with col_asset3:
                top_location = assets["location_id"].mode()[0] if not assets.empty else ""
                st.metric("Busiest Location", location_label(top_location) if top_location else "N/A")


# ============================================================================
# MAIN APPLICATION
# ============================================================================
def main() -> None:
    """App entry point (routing + one-time initialization)."""
    st.set_page_config(
        page_title="Reporting Tool @ HSG",
        page_icon="üèõÔ∏è",
        layout="centered",
        initial_sidebar_state="expanded",
    )

    config = get_config()

    show_logo()
    st.sidebar.markdown("### Navigation")

    section = st.sidebar.radio(
        "Select section:",
        ["üìã Reporting Tool", "üìÖ Booking & Tracking", "üìä Overview"],
        label_visibility="collapsed",
    )

    if section == "üìã Reporting Tool":
        page = st.sidebar.selectbox(
            "Select page:",
            ["üìù Submit Issue", "üìã View Issues", "üîß Admin Panel"],
            label_visibility="collapsed",
        )
        page_map = {
            "üìù Submit Issue": "Submission Form",
            "üìã View Issues": "Submitted Issues",
            "üîß Admin Panel": "Overwrite Status",
        }
        current_page = page_map[page]
    elif section == "üìÖ Booking & Tracking":
        page = st.sidebar.selectbox(
            "Select page:",
            ["üìÖ Book Assets", "üìç Track Assets"],
            label_visibility="collapsed",
        )
        page_map = {"üìÖ Book Assets": "Booking", "üìç Track Assets": "Asset Tracking"}
        current_page = page_map[page]
    else:
        current_page = "Overview Dashboard"

    try:
        st.image(
            "campus_header.jpeg",
            caption="Campus of the University of St.Gallen (HSG), St.Gallen, Switzerland",
            use_container_width=True,
        )
    except FileNotFoundError:
        # UI fallback: keep the app usable even if the header image is missing.
        st.caption("Reporting Tool @ HSG")

    try:
        con = get_connection()
        init_db(con)
        migrate_db(con)
        init_booking_table(con)
        init_assets_table(con)
        seed_assets(con)
        sync_asset_statuses_from_bookings(con)
        send_weekly_report_if_due(con, config=config)
    except Exception as e:
        st.error(f"‚ùå Database initialization failed: {e}")
        logger.critical("Database initialization error: %s", e)
        return

    st.title("Reporting Tool @ HSG")

    page_functions = {
        "Submission Form": lambda: page_submission_form(con, config=config),
        "Submitted Issues": lambda: page_submitted_issues(con),
        "Booking": lambda: page_booking(con),
        "Asset Tracking": lambda: page_assets(con),
        "Overview Dashboard": lambda: page_overview_dashboard(con),
        "Overwrite Status": lambda: page_overwrite_status(con, config=config),
    }

    if current_page in page_functions:
        page_functions[current_page]()
    else:
        st.error(f"Page '{current_page}' not found.")

    st.sidebar.markdown("---")
    st.sidebar.caption(f"¬© {datetime.now().year} University of St.Gallen")
    st.sidebar.caption(f"Last updated: {now_zurich().strftime('%Y-%m-%d %H:%M')}")


# ============================================================================
# APPLICATION ENTRY POINT
# ============================================================================
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        # Catch-all so an unexpected exception still produces a helpful UI message for graders.
        logger.critical("Application crashed: %s", e, exc_info=True)

        st.error(
            "‚ö†Ô∏è **Application Error**\n\n"
            "The application encountered an unexpected error. Try:\n"
            "1) Refresh the page\n"
            "2) Check your internet connection\n"
            "3) Contact support if the problem persists\n\n"
            "Error details (for administrators):\n"
            f"```\n{str(e)}\n```"
        )

        try:
            if get_config().debug:
                import traceback

                st.code(traceback.format_exc(), language="python")
        except Exception:
            # Debug output is best-effort; the UI should not crash while rendering an error.
            pass
